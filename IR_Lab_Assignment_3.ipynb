{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyQVkBbOWRJEe/zoR2GDDn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DEEPAK-RAMGIRI/NLP-Natural-Language-Processor-/blob/main/IR_Lab_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "EvTtyOucDIYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fOAcbqQAeqR",
        "outputId": "75adb900-be43-417f-cdbc-a025da912e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIpIEZd5_jo6"
      },
      "outputs": [],
      "source": [
        "story = \"ONE PIECE is a legendary high-seas quest unlike any other. Luffy is a young adventurer who has longed for a life of freedom ever since he can remember. He sets off from his small village on a perilous journey to find the legendary fabled treasure, ONE PIECE, to become King of the Pirates!\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nltk.word_tokenize(story)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Wi-PaUlAPdD",
        "outputId": "b6f0c897-8cb2-4947-f1f9-a0e527c62bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ONE', 'PIECE', 'is', 'a', 'legendary', 'high-seas', 'quest', 'unlike', 'any', 'other', '.', 'Luffy', 'is', 'a', 'young', 'adventurer', 'who', 'has', 'longed', 'for', 'a', 'life', 'of', 'freedom', 'ever', 'since', 'he', 'can', 'remember', '.', 'He', 'sets', 'off', 'from', 'his', 'small', 'village', 'on', 'a', 'perilous', 'journey', 'to', 'find', 'the', 'legendary', 'fabled', 'treasure', ',', 'ONE', 'PIECE', ',', 'to', 'become', 'King', 'of', 'the', 'Pirates', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "filtered_tokens = []\n",
        "for i in tokens:\n",
        "  if i not in stop_words:\n",
        "    filtered_tokens.append(i)\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUUy1HkHB3rU",
        "outputId": "9a50ccec-9dfe-4045-e2d1-627197bce39c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ONE', 'PIECE', 'legendary', 'high-seas', 'quest', 'unlike', '.', 'Luffy', 'young', 'adventurer', 'longed', 'life', 'freedom', 'ever', 'since', 'remember', '.', 'He', 'sets', 'small', 'village', 'perilous', 'journey', 'find', 'legendary', 'fabled', 'treasure', ',', 'ONE', 'PIECE', ',', 'become', 'King', 'Pirates', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bow = {}\n",
        "for i in filtered_tokens:\n",
        "  if i in bow:\n",
        "    bow[i] += 1\n",
        "  else:\n",
        "    bow[i] = 1\n",
        "sorted(bow.items(),key = lambda x:x[1],reverse=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8X9gZZSAuB9",
        "outputId": "8c8494ce-baed-4700-a931-c172490e8a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ONE', 2),\n",
              " ('PIECE', 2),\n",
              " ('legendary', 2),\n",
              " ('.', 2),\n",
              " (',', 2),\n",
              " ('high-seas', 1),\n",
              " ('quest', 1),\n",
              " ('unlike', 1),\n",
              " ('Luffy', 1),\n",
              " ('young', 1),\n",
              " ('adventurer', 1),\n",
              " ('longed', 1),\n",
              " ('life', 1),\n",
              " ('freedom', 1),\n",
              " ('ever', 1),\n",
              " ('since', 1),\n",
              " ('remember', 1),\n",
              " ('He', 1),\n",
              " ('sets', 1),\n",
              " ('small', 1),\n",
              " ('village', 1),\n",
              " ('perilous', 1),\n",
              " ('journey', 1),\n",
              " ('find', 1),\n",
              " ('fabled', 1),\n",
              " ('treasure', 1),\n",
              " ('become', 1),\n",
              " ('King', 1),\n",
              " ('Pirates', 1),\n",
              " ('!', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "jZuiIocnEFxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"The dog barked at the fox.\",\n",
        "    \"Foxes are quick and smart animals.\",\n",
        "    \"Dogs and foxes don't always get along.\",\n",
        "]"
      ],
      "metadata": {
        "id": "NYL2OJQqFd7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "preprocessed = []\n",
        "\n",
        "for i in corpus:\n",
        "    tokens = nltk.word_tokenize(i.lower())\n",
        "    filtered_tokens = [word for word in tokens if word.isalpha() and word not in stopwords]\n",
        "    preprocessed.append(\" \".join(filtered_tokens))\n",
        "\n",
        "print(\"Preprocessed Corpus:\")\n",
        "print(preprocessed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq5HzC_VFwL4",
        "outputId": "c9c4b035-e415-4fb6-b899-b9709a7b7230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed Corpus:\n",
            "['quick brown fox jumps lazy dog', 'dog barked fox', 'foxes quick smart animals', 'dogs foxes always get along']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(preprocessed)\n",
        "\n",
        "\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "print(\"\\nBag-of-Words Term-Document Matrix:\")\n",
        "print(bow_df)\n",
        "\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "frequencies = np.asarray(bow_matrix.sum(axis=0)).flatten()\n",
        "\n",
        "print(\"\\nTerms and their Frequencies:\")\n",
        "for term, freq in zip(terms, frequencies):\n",
        "    print(f\"{term}: {freq}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0z5eIK_GdJG",
        "outputId": "d2187e09-b953-4522-da17-eb695559bef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag-of-Words Term-Document Matrix:\n",
            "   along  always  animals  barked  brown  dog  dogs  fox  foxes  get  jumps  \\\n",
            "0      0       0        0       0      1    1     0    1      0    0      1   \n",
            "1      0       0        0       1      0    1     0    1      0    0      0   \n",
            "2      0       0        1       0      0    0     0    0      1    0      0   \n",
            "3      1       1        0       0      0    0     1    0      1    1      0   \n",
            "\n",
            "   lazy  quick  smart  \n",
            "0     1      1      0  \n",
            "1     0      0      0  \n",
            "2     0      1      1  \n",
            "3     0      0      0  \n",
            "\n",
            "Terms and their Frequencies:\n",
            "along: 1\n",
            "always: 1\n",
            "animals: 1\n",
            "barked: 1\n",
            "brown: 1\n",
            "dog: 2\n",
            "dogs: 1\n",
            "fox: 2\n",
            "foxes: 2\n",
            "get: 1\n",
            "jumps: 1\n",
            "lazy: 1\n",
            "quick: 2\n",
            "smart: 1\n"
          ]
        }
      ]
    }
  ]
}