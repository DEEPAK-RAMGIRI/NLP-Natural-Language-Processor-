{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt34GwbbMFtAMRGZMCwHum",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DEEPAK-RAMGIRI/NLP-Natural-Language-Processor-/blob/main/LAB_005.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WORD EMBEDDING"
      ],
      "metadata": {
        "id": "ALnFiWFuMndk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import gensim.downloader as api\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "5ZZ9w601MsLy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF1e9Lq_Jli8",
        "outputId": "5ef3ce4b-7e21-45fa-f104-53beada1815b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "word_vectors = api.load(\"glove-wiki-gigaword-100\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def explore_embeddings(word):\n",
        "  similar_words = word_vectors.most_similar(word)\n",
        "  print(f\"Words most similar to '{word} are: \")\n",
        "  for similar_word,similarity in similar_words:\n",
        "    print(f\"{similar_word}:{similarity:.4f}\")\n",
        "explore_embeddings(\"king\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMjQqUWRMxu1",
        "outputId": "c5dfcbda-14a2-41a6-96fa-f5442234d9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words most similar to 'king are: \n",
            "prince:0.7682\n",
            "queen:0.7508\n",
            "son:0.7021\n",
            "brother:0.6986\n",
            "monarch:0.6978\n",
            "throne:0.6920\n",
            "kingdom:0.6811\n",
            "father:0.6802\n",
            "emperor:0.6713\n",
            "ii:0.6676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VISUALIZING USING WORD EMBEDDING"
      ],
      "metadata": {
        "id": "_qaWO2TXO0S-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['king','queen','man','woman','paris','france','london','england']\n",
        "word_vecs = [word_vectors[word] for word in words]\n",
        "pcs = PCA(n_components=2)\n",
        "result = pcs.fit_transform(word_vecs)"
      ],
      "metadata": {
        "id": "2poNvsx9MzX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hQVVhMRcOEEf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}